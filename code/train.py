"""
author: Florian Krach
"""

# ==============================================================================
import torch
import tqdm
import numpy as np
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
import os, sys
import pandas as pd
import json
import time
import socket
import matplotlib
import matplotlib.colors
import gc
import warnings

import data_utils
import models
import config
import extras

try:
    from telegram_notifications import send_bot_message as SBM
except Exception:
    SBM = config.SendBotMessage()

# ==============================================================================
USE_GPU = False
ANOMALY_DETECTION = False
DATA_NB_JOBS = 4

# check whether running on computer or server
if 'ada-' not in socket.gethostname():
    SERVER = False
    SEND = False
    NB_CPUS = 1
else:
    SERVER = True
    SEND = True
    NB_CPUS = 2
    matplotlib.use('Agg')
print(socket.gethostname())
print('SERVER={}'.format(SERVER))

import matplotlib.pyplot as plt


# ==============================================================================
# Global variables
CHAT_ID = config.CHAT_ID
ERROR_CHAT_ID = config.ERROR_CHAT_ID

data_path = config.data_path
saved_models_path = config.saved_models_path
flagfile = config.flagfile

METR_COLUMNS = [
    'epoch', 'train_time', 'eval_time',
    'train_lossD', 'train_lossG',
    'eval_expected_utility', 'eval_penalty', 'eval_penalty_drift',
    'eval_path_wise_penalties',
    'analytic_sol_expected_utility', 'analytic_sol_penalty',
    'analytic_sol_penalty_drift',
    'eval_dist',
    'eval_expected_util_with_analytic_par', 'eval_penalty_vs_analytic_sig',
    'eval_penalty_drift_vs_analytic_mu',
    'eval_expected_util_with_noisy_par', 'eval_expected_util_with_GARCH',
    'path_wise_penalty_scaled_sum',
    'eval_expected_utility_with_ref_strategy',
    'eval_expected_utility_with_ref_strategy_noisy_par',
]



# ==============================================================================
# Functions
makedirs = data_utils.makedirs


def train(
        anomaly_detection=None, n_dataset_workers=None, use_gpu=None,
        nb_cpus=None, send=None,
        model_id=None, seed=364, save_every=1,
        test_size=0.2,
        data_dict=None,
        epochs=50,
        learning_rate_D=1e-4, learning_rate_G=1e-4,
        lr_scheduler_D=None, lr_scheduler_G=None,
        beta1_D=0.9, beta2_D=0.999, beta1_G=0.9, beta2_G=0.999,
        opt_steps_D_G=None, batch_size=50, penalty_scaling_factor=1.,
        penalty_scaling_factor_drift=None,
        utility_func="log", penalty_func="norm-2", penalty_func_drift=None,
        penalty_function_ref_value=0,
        penalty_function_ref_value_drift=None,
        path_wise_penalty=None,
        gen_dict=None, disc_dict=None,
        saved_models_path=saved_models_path,
        **options,
):
    """
    :param model_id: int or None, identifying the model that is trained
    :param seed: int or None, to make training reproducible
    :param test_size: float, ratio of test data
    :param save_every: int, after how many epochs in training loop to save
    :param data_dict: str (name of a data_dict in config.py) to generate/load
            datasets, if None falls back to ids specified below
    :param epochs: int, how many epochs to train
    :param learning_rate_D: float
    :param learning_rate_G: float
    :param lr_scheduler_D: None or dict with keys "step" and "gamma" for
            learning rate scheduler for discriminator of P model
    :param lr_scheduler_G: None or dict with keys "step" and "gamma" for
            learning rate scheduler for generator of P model
    :param beta1_D: float, beta values for Adam optimizer in disc
    :param beta2_D: float, beta values for Adam optimizer in disc
    :param beta1_G: float, beta values for Adam optimizer in gen
    :param beta2_G: float, beta values for Adam optimizer in gen
    :param opt_steps_D_G: list of 2 ints, [n,m], do n disc steps before doing m
            gen steps, if None defaults to [1,1]
    :param batch_size: int
    :param penalty_scaling_factor: float
    :param penalty_scaling_factor_drift: None or float, scaling of drift penalty
    :param penalty_function_ref_value: float or torch.tensor of needed size,
            reference value for volatility in the penalty function
    :param penalty_function_ref_value_drift: None, float or array of needed size
            reference value for drift in the penalty function
    :param utility_func: str,
    :param penalty_func: str,
    :param penalty_func_drift: str,
    :param path_wise_penalty: None or list of dicts, if not None: each list
            entry is a dictionary that describes one penalty term that is
            applied to the paths generated by the model. each dict has the
            following keys:
                - is_mean_penalty: bool, whether penalty is applied to
                    expectation over paths (is_mean_penalty=True), or
                    expectation of penalty is used (is_mean_penalty=False(
                - path_functional: str, that returns a function when eval is
                    applied to it. e.g. name of a function defined in config.py
                    (eg. "config.get_quad_covar"). this function has to take the
                    torch.tensor representing all generated paths and return a
                    torch.tensor of shape [batch-size, ...] (in case:
                    is_mean_penalty=False) or [...] (in case:
                    is_mean_penalty=True)
                - ref_value: list that can be made to a torch.tensor of same
                    shape as output of path_functional (without batch-size in
                    case is_mean_penalty=False)
                - penalty_func: str, that returns a function when eval is
                    applied to it. this function has to take two inputs, i.e.
                    the output of path_functional and the ref value and return a
                    torch.tensor of shape [batch-size,] penalty term
                - scaling_factor: float, the scaling factor for the penalty term
    :param gen_dict: dict, with all keys to init the investor (generation)
            network. keys:
            - name:             name of the architectur, see models.MODEL_DICT,
                                depending on the wanted model, different other
                                kwargs need to be provided
            - dropout_rate:     optional, defaults to 0.0, dropout for all
                                networks
            - bias:             bool, defaults to True, whether the networks use
                                a bias True
            - hidden_desc:      array, (RNN only), defining the NN for hidden
                                evolution, each entry is array (size, activ)
                                describing one layer, where size is int (number
                                of neurons) and activ is a str for a supported
                                activation function in config.activation_dict
            - readout_desc:     array, (RNN only), similar to hidden_desc
            - hidden_size:      int, (RNN only), hidden size  of the RNN
    :param disc_dict: dict, defining the discriminator network
            (cf. COT-GAN), similar to gen_dict, but:
            - conditional_desc:     not used, always set to None
            - output_size:      int, how many features are used for h and M
    :param options: additional kwargs, supported keys:
            - parallel:     bool, used by parallel_train.parallel_training
            - resume_training:  bool, used by parallel_train.parallel_training
            - load_best:    bool, whether to load best or last model when
                            resuming training
            - initial_wealth:   float, th starting wealth, default: 1
            - use_penalty_for_gen:  bool, whether to use only expected utility
                            or expected utility plus penalty for generator
                            optimization
            - use_log_return:   bool, whether to use standard Euler scheme
                            (False, default) or euler scheme for log returns
                            (True)
            - eval_only:    bool, whether to only evaluate (the loaded model)
            - use_opponents_output: bool, whether disc and gen use the output of
                            each other as input,
                            ATTENTION: currently not supported
            - eval_on_train:    bool, whether to evaluate the model on the train
                            set (instead of test set)
            - trans_cost_perc:  float >= 0, percentage transaction costs
            - trans_cost_base:  float >= 0, base transaction costs per
                            transaction
            - eval_noise_std:   None or float, default: None. The std of the
                            noise for noisy-sigmas used for evaluation during
                            training. For each path of the validation set, a
                            different noisy sigma is used, s.t. the evaluation
                            needs the same time.
            - eval_noise_std_drift: None or float, default: None. The std of the
                            noise for noisy-mus used for evaluation during
                            training. For each path of the validation set, a
                            different noisy mu is used, s.t. the evaluation
                            needs the same time.
            - eval_noise_seed:  int, default: 0
            - eval_noise_type:  str, one of {"const", "nonconst", "cumulative"}
                            whether the noise for evaluations is constant over
                            time ("const"; default) or non-constant by adding a
                            different random noise at each time, like noise
                            around base values ("nonconst") or non-constant by
                            adding cumulative noise, like a BM path
                            ("cumulative")
            - eval_model_dict:  dict or None, description of the evaluation
                            model; needed keys:
                                name: str, one of {"GARCH"}
                                params: dict, containing named params to init
                                    model, keys (GARCH): [p, q, dist, mean]
                                noise: dict, containing the info how to sample
                                    noisy versions of fitted params,
                                    keys (GARCH): [params_quantile, rho_std]
                                        - params_quantile: the quantile to use
                                            for fitted params (making use of
                                            the std_err of the fit)
                                        - rho_std: the scaling for noise on rho
                                fit_seq_len: int, length of sequence to fit the
                                    model to
            - gradient_clip_norm_gen:    None or float, if float use gradient
                            clipping for generator s.t. the gradient norm is
                            clipped with given value
            - gradient_clip_norm_disc:    None or float, if float use gradient
                            clipping for discriminator s.t. the gradient norm is
                            clipped with given value
            - numerically_stabilised_training: bool, whether to lower bound
                            quantities that should stay positive by small
                            positive number in the training; default: False
            - input_increments: bool, whether to use increments of S and X as
                            input to NNs instead of S and X directly;
                            default: false
            - use_general_SDE: bool, whether to use the SDE form similar to
                            Black--Scholes, i.e. dS/S = mu*dt+sigma*dW (False),
                            or general SDE dS = mu*dt+sigma*dW (True);
                            default: False
            - epochs_D_G:   [int, int] or None, number of epochs for
                            discriminator and generator, otherwise use
            - weight_decay: float, weight decay for optimizer, default: 0 (i.e.
                            no weight decay)
            - train_readout_only:   bool, whether to only train the readout part
                            of the generator
            - train_penalty_threshold:  float, threshold for penalty term, if
                            the penalty is smaller than this threshold, then
                            also the expected utility is trained by the disc,
                            otherwise only the penalty is trained
            - which_best:   str, defines which validation criterion to use for
                            saving the "best" model. one of
                            {'eval_expected_utility',
                            'eval_expected_util_with_analytic_par',
                            'eval_expected_util_with_noisy_par',
                            'eval_expected_util_with_GARCH',
                            'path_wise_penalty_scaled_sum'}
                            default: if eval_model_dict is given use
                            eval_expected_util_with_GARCH, elif eval_noise_std
                            is given then use eval_expected_util_with_noisy_par,
                            elif analytic solution available use
                            eval_expected_util_with_analytic_sig, else use
                            eval_expected_utility
            - ref_strategy: str, defining a function (via lambda notation) that
                            takes (S, X, t, current_amount) as input and returns
                            the reference strategy pi_ref. default: None, i.e.
                            no reference
    """
    # needed for parallel training (otherwise the child processes
    #   don't have the flags)
    global ANOMALY_DETECTION, USE_GPU, SEND, N_CPUS, N_DATASET_WORKERS
    if anomaly_detection is not None:
        ANOMALY_DETECTION = anomaly_detection
    if use_gpu is not None:
        USE_GPU = use_gpu
    if send is not None:
        SEND = send
    if nb_cpus is not None:
        NB_CPUS = nb_cpus
    if n_dataset_workers is not None:
        N_DATASET_WORKERS = n_dataset_workers
    initial_print = "model-id: {}\n".format(model_id)

    if ANOMALY_DETECTION:
        torch.autograd.set_detect_anomaly(True)
        torch.manual_seed(0)
        np.random.seed(0)
        torch.use_deterministic_algorithms(True)

    # set number of CPUs
    print('nb CPUs: {}'.format(NB_CPUS))
    torch.set_num_threads(NB_CPUS)

    # get the device for torch
    if USE_GPU and torch.cuda.is_available():
        gpu_num = 0
        device = torch.device("cuda:{}".format(gpu_num))
        torch.cuda.set_device(gpu_num)
        initial_print += '\nusing GPU'
    else:
        device = torch.device("cpu")
        initial_print += '\nusing CPU'

    # get params_dict
    params_dict = {
        'seed': seed, 'data_dict': data_dict,
        "test_size": test_size,
        'epochs': epochs,
        'learning_rate_D': learning_rate_D, 'learning_rate_G': learning_rate_G,
        'lr_scheduler_D': lr_scheduler_D, 'lr_scheduler_G': lr_scheduler_G,
        'beta1_D': beta1_D, 'beta2_D': beta2_D,
        'beta1_G': beta1_G, 'beta2_G': beta2_G,
        'batch_size': batch_size, 'opt_steps_D_G': opt_steps_D_G,
        'gen_dict': gen_dict, 'disc_dict': disc_dict,
        'penalty_scaling_factor': penalty_scaling_factor,
        'utility_func': utility_func, 'penalty_func': penalty_func,
        'penalty_function_ref_value': penalty_function_ref_value,
        'penalty_func_drift': penalty_func_drift,
        'penalty_scaling_factor_drift': penalty_scaling_factor_drift,
        'penalty_function_ref_value_drift': penalty_function_ref_value_drift,
        'path_wise_penalty': path_wise_penalty,
        'options': options}
    desc = json.dumps(params_dict, sort_keys=True)

    # get overview file
    resume_training = False
    if ('parallel' in options and options['parallel'] is False) or \
            ('parallel' not in options):
        model_overview_file_name = '{}model_overview.csv'.format(
            saved_models_path)
        makedirs(saved_models_path)
        if not os.path.exists(model_overview_file_name):
            df_overview = pd.DataFrame(data=None,
                                       columns=['id', 'description'])
            max_id = 0
        else:
            df_overview = pd.read_csv(model_overview_file_name, index_col=0)
            max_id = np.max(df_overview['id'].values)

        # get model_id, model params etc.
        if model_id is None:
            model_id = max_id + 1
        if model_id not in df_overview['id'].values:
            initial_print += '\nnew model_id={}'.format(model_id)
            df_ov_app = pd.DataFrame([[model_id, desc]],
                                     columns=['id', 'description'])
            df_overview = pd.concat([df_overview, df_ov_app],
                                    ignore_index=True)
            df_overview.to_csv(model_overview_file_name)
        else:
            initial_print += '\nmodel_id already exists -> resume training'
            resume_training = True
            desc = (df_overview['description'].loc[
                df_overview['id'] == model_id]).values[0]
            params_dict = json.loads(desc)
            options = params_dict["options"]
    initial_print += '\nmodel params:\n{}'.format(desc)
    if 'resume_training' in options and options['resume_training'] is True:
        resume_training = True

    # get all needed paths
    model_path = '{}id-{}/'.format(saved_models_path, model_id)
    makedirs(model_path)
    model_path_save_last = '{}last_checkpoint/'.format(model_path)
    model_path_save_best = '{}best_checkpoint/'.format(model_path)
    makedirs(model_path_save_last)
    makedirs(model_path_save_best)
    model_metric_file = '{}metric_id-{}.csv'.format(model_path, model_id)
    plot_save_path = '{}plots/'.format(model_path)

    if params_dict['seed']:
        torch.manual_seed(params_dict['seed'])
        np.random.seed(params_dict['seed'])

    if data_dict is None:
        raise ValueError("Please provide a valid data_dict")

    data_dict = eval("config.{}".format(data_dict))

    # get datasets and dataloaders
    eval_on_train = False
    if "eval_on_train" in options:
        eval_on_train = options["eval_on_train"]
    train_idx, val_idx = train_test_split(
        np.arange(data_dict["nb_samples"]), test_size=test_size,
        random_state=seed)
    data_train = data_utils.SDEIncrements(
        load=True, verbose=1, idx=train_idx, **data_dict)
    data_val = data_utils.SDEIncrements(
        load=True, verbose=1, idx=val_idx, **data_dict)
    if eval_on_train:
        data_val = data_train
    dl_train = DataLoader(
        dataset=data_train, collate_fn=data_utils.custom_collate_fn,
        shuffle=True, batch_size=batch_size, num_workers=N_DATASET_WORKERS)
    dl_val = DataLoader(
        dataset=data_val, collate_fn=data_utils.custom_collate_fn,
        shuffle=False, batch_size=len(data_val), num_workers=N_DATASET_WORKERS)

    dimension = data_train.dimension
    dt = data_train.dt
    r = data_train.r
    S0 = data_train.S0
    nb_steps = data_train.nb_steps

    # get eval model
    eval_model = None
    eval_model_dict = None
    if "eval_model_dict" in options:
        eval_model_dict = options["eval_model_dict"]
        eval_model = extras.get_eval_model(
            name=eval_model_dict["name"], params=eval_model_dict["params"],
            data_train=data_train, fit_seq_len=eval_model_dict["fit_seq_len"],
            S0=S0, dt=dt, penalty_function_ref_value=penalty_function_ref_value,
            penalty_function_ref_value_drift=penalty_function_ref_value_drift,
            nb_steps=nb_steps)

    # get model and optimizer
    initial_wealth = 1
    if "initial_wealth" in options:
        initial_wealth = options["initial_wealth"]
    use_penalty_for_gen = False
    if "use_penalty_for_gen" in options:
        use_penalty_for_gen = options["use_penalty_for_gen"]
    use_log_return = False
    if "use_log_return" in options:
        use_log_return = options["use_log_return"]
    use_opponents_output = False
    if "use_opponents_output" in options:
        use_opponents_output = options["use_opponents_output"]
    trans_cost_base = 0.
    trans_cost_perc = 0.
    if "trans_cost_perc" in options:
        trans_cost_perc = options["trans_cost_perc"]
    if "trans_cost_base" in options:
        trans_cost_base = options["trans_cost_base"]
    eval_noise_std = None
    if 'eval_noise_std' in options:
        eval_noise_std = options['eval_noise_std']
    eval_noise_std_drift = None
    if 'eval_noise_std_drift' in options:
        eval_noise_std_drift = options['eval_noise_std_drift']
    eval_noise_seed = 0
    if 'eval_noise_seed' in options:
        eval_noise_seed = options['eval_noise_seed']
    eval_noise_type = "const"
    if 'eval_noise_type' in options:
        eval_noise_type = options['eval_noise_type']
    gradient_clip_norm_gen = None
    if 'gradient_clip_norm_gen' in options:
        gradient_clip_norm_gen = options['gradient_clip_norm_gen']
    gradient_clip_norm_disc = None
    if 'gradient_clip_norm_disc' in options:
        gradient_clip_norm_disc = options['gradient_clip_norm_disc']
    numerically_stabilised_training = False
    if 'numerically_stabilised_training' in options:
        numerically_stabilised_training = \
            options["numerically_stabilised_training"]
    input_increments = False
    if 'input_increments' in options:
        input_increments = options['input_increments']
    use_general_SDE = False
    if 'use_general_SDE' in options:
        use_general_SDE = options['use_general_SDE']
    weight_decay = 0
    if 'weight_decay' in options:
        weight_decay = options['weight_decay']
    train_readout_only = False
    if "train_readout_only" in options:
        train_readout_only = options["train_readout_only"]
    train_penalty_threshold = None
    if "train_penalty_threshold" in options:
        train_penalty_threshold = options["train_penalty_threshold"]

    if opt_steps_D_G is None:
        opt_steps_D_G = [1,1]
    epochs_D_G = None
    if 'epochs_D_G' in options:
        epochs_D_G = options['epochs_D_G']

    ref_strategy = None
    if "ref_strategy" in options:
        ref_strategy = eval(options["ref_strategy"])

    model = models.MinMaxModel(
        dimension=dimension, scaling_coeff=penalty_scaling_factor,
        utility_func=utility_func, penalty_func=penalty_func,
        penalty_function_ref_value=penalty_function_ref_value,
        penalty_function_ref_value_drift=penalty_function_ref_value_drift,
        path_wise_penalty=path_wise_penalty,
        gen_dict=gen_dict, disc_dict=disc_dict,
        dt=dt, r=r, S0=S0, nb_steps=nb_steps,
        initial_wealth=initial_wealth, use_penalty_for_gen=use_penalty_for_gen,
        use_log_return=use_log_return,
        use_opponents_output=use_opponents_output,
        trans_cost_base=trans_cost_base, trans_cost_perc=trans_cost_perc,
        penalty_func_drift=penalty_func_drift,
        scaling_coeff_drift=penalty_scaling_factor_drift,
        numerically_stabilised_training=numerically_stabilised_training,
        input_increments=input_increments, use_general_SDE=use_general_SDE,
        train_penalty_threshold=train_penalty_threshold,)
    scheduler_D, scheduler_G = None, None
    optimizer_D = None
    if model.discriminator is not None:
        optimizer_D = torch.optim.Adam(
            model.discriminator.parameters(), lr=learning_rate_D,
            betas=(beta1_D, beta2_D), weight_decay=weight_decay)
        if lr_scheduler_D:
            scheduler_D = torch.optim.lr_scheduler.StepLR(
                optimizer_D, step_size=lr_scheduler_D["step"],
                gamma=lr_scheduler_D["gamma"])
    if train_readout_only:
        optimizer_G = torch.optim.Adam(
            model.generator.readout.parameters(), lr=learning_rate_G,
            betas=(beta1_G, beta2_G), weight_decay=weight_decay)
    else:
        optimizer_G = torch.optim.Adam(
            model.generator.parameters(), lr=learning_rate_G,
            betas=(beta1_G, beta2_G), weight_decay=weight_decay)
    if lr_scheduler_G:
        scheduler_G = torch.optim.lr_scheduler.StepLR(
            optimizer_G, step_size=lr_scheduler_G["step"],
            gamma=lr_scheduler_G["gamma"])

    # get analytic reference solution
    analytic_exp_util, analytic_penalty, analytic_penalty_drift, analytic_sig, \
    analytic_pi, analytic_mu = model.get_reference_solution(
        dWs=data_val.increments)
    initial_print += "\n\nanalytic solution: expected-utility={}, " \
                     "penalty={}, penalty_drift={}, " \
                     "sigma={}, mu={}, pi={}".format(
        analytic_exp_util, analytic_penalty, analytic_penalty_drift,
        analytic_sig, analytic_mu, analytic_pi)

    which_best = 'eval_expected_utility'
    if analytic_exp_util is not None:
        which_best = 'eval_expected_util_with_analytic_par'
    if eval_noise_std is not None:
        which_best = 'eval_expected_util_with_noisy_par'
    if eval_model is not None:
        which_best = 'eval_expected_util_with_GARCH'
    if 'which_best' in options:
        which_best = options['which_best']

    best_is_small = False
    if which_best in ['path_wise_penalty_scaled_sum']:
        best_is_small = True

    pwp_scalings = None
    if path_wise_penalty is not None:
        pwp_scalings = np.array(
            [x["scaling_factor"] for x in path_wise_penalty])

    # load saved model if wanted/possible
    if best_is_small:
        best_eval_loss = np.infty
    else:
        best_eval_loss = -np.infty
    metr_columns = METR_COLUMNS
    metric_app = []
    if resume_training:
        initial_print += '\nload saved model ...'
        try:
            if 'load_best' in options and options['load_best']:
                models.get_ckpt_model(
                    model_path_save_best, model, [optimizer_G, optimizer_D],
                    [scheduler_G, scheduler_D], device
                )
            else:
                models.get_ckpt_model(
                    model_path_save_last, model, [optimizer_G, optimizer_D],
                    [scheduler_G, scheduler_D], device
                )
        except Exception as e:
            initial_print += '\nloading Model failed -> initiate new model'
            initial_print += '\nException:\n{}'.format(e)
            resume_training = False
        if os.path.exists(model_metric_file):
            df_metric = pd.read_csv(model_metric_file, index_col=0)
            if best_is_small:
                best_eval_loss = np.min(df_metric[which_best].values)
            else:
                best_eval_loss = np.max(df_metric[which_best].values)
            model.epoch += 1
            initial_print += '\nepoch: {}'.format(
                model.epoch)
    initial_print += '\nbest eval loss: {:.5f}'.format(best_eval_loss)
    if not resume_training:
        initial_print += '\ninitiate new Model ...'
        df_metric = pd.DataFrame(columns=metr_columns)

    # ------- DEFINE TRAINING FUNCTIONS --------
    def one_epoch(eval_only=False, train_gen_or_disc=None):
        nonlocal best_eval_loss
        nonlocal df_metric
        nonlocal metric_app
        print("-"*80)
        t = time.time()
        model.train()  # set model in train mode (e.g. BatchNorm)
        train_loss_D = 0
        train_loss_G = 0
        count_D = 0
        count_G = 0
        if not eval_only:
            for i, b in tqdm.tqdm(enumerate(dl_train)):
                # identify whether gen or disc should be updated
                if train_gen_or_disc is None:
                    if i % sum(opt_steps_D_G) < opt_steps_D_G[0]:
                        disc_ = True
                        optimizer_D.zero_grad()
                        which = "disc"
                    else:
                        disc_ = False
                        optimizer_G.zero_grad()
                        which = "gen"
                elif train_gen_or_disc == 0:
                    disc_ = True
                    optimizer_D.zero_grad()
                    which = "disc"
                else:
                    disc_ = False
                    optimizer_G.zero_grad()
                    which = "gen"

                dWs = b["increments"]
                if "init_vals" in b:
                    init_vals = b["init_vals"]
                else:
                    init_vals = None

                loss = model(
                    dWs, which=which, DEBUG=ANOMALY_DETECTION,
                    init_vals=init_vals)
                loss.backward()

                if disc_:
                    count_D += 1
                    if optimizer_D is not None:
                        if gradient_clip_norm_disc is not None:
                            torch.nn.utils.clip_grad_norm_(
                                model.discriminator.parameters(),
                                max_norm=gradient_clip_norm_disc)
                        optimizer_D.step()
                    train_loss_D += loss.detach().numpy()
                else:
                    count_G += 1
                    if optimizer_G is not None:
                        if gradient_clip_norm_gen is not None:
                            torch.nn.utils.clip_grad_norm_(
                                model.generator.parameters(),
                                max_norm=gradient_clip_norm_gen)
                        optimizer_G.step()
                    train_loss_G += loss.detach().numpy()
            if scheduler_D is not None:
                scheduler_D.step()
            if scheduler_G is not None:
                scheduler_G.step()
            train_loss_D = train_loss_D / count_D if count_D > 0 else np.nan
            train_loss_G = train_loss_G / count_G if count_G > 0 else np.nan
            train_time = time.time() - t
        else:
            train_time = np.nan
            train_loss_D = np.nan
            train_loss_G = np.nan

        # -------- evaluation --------
        t = time.time()
        with torch.no_grad():
            model.eval()  # set model in evaluation mode
            expected_util = 0
            count = 0
            penalty = 0
            penalty_drift = 0
            expected_util_with_ref = 0
            expected_util_with_noisy_sig = 0
            expected_util_with_GARCH = 0
            expected_util_with_ref_strategy = 0
            expected_util_noisy_ref_strat = 0
            penalty_vs_ref = 0
            penalty_drift_vs_ref = 0
            if path_wise_penalty is not None:
                pwps = np.zeros(len(path_wise_penalty))
            else:
                pwps = np.array([])
            np.random.seed(eval_noise_seed)
            for i, b in enumerate(dl_val):
                dWs = b["increments"]
                if "init_vals" in b:
                    init_vals = b["init_vals"]
                else:
                    init_vals = None
                exp_util_, penalty_, penalty_drift_, pwps_ = model(
                    dWs, which="both", init_vals=init_vals)
                expected_util += exp_util_.detach().numpy()
                penalty += penalty_.detach().numpy()
                penalty_drift += penalty_drift_.detach().numpy()
                pwps += np.array([x.detach().numpy() for x in pwps_])
                if analytic_sig is not None:
                    exp_util2_, penalty2_, penalty_drift2_, _, _, _ = \
                        model.evaluate(
                            dWs, init_vals=init_vals,
                            ref_params=analytic_sig.reshape((1,-1)).repeat(
                                repeats=nb_steps, axis=0),
                            ref_params_drift=analytic_mu.reshape((1,-1)).repeat(
                                repeats=nb_steps, axis=0))
                    expected_util_with_ref += exp_util2_.detach().numpy()
                    penalty_vs_ref += penalty2_.detach().numpy()
                    penalty_drift_vs_ref += penalty_drift2_.detach().numpy()
                rand_sig, rand_mu = None, None
                noisy_eval = False
                bs = dWs.shape[0]
                if eval_noise_std is not None:
                    rand_sig0 = np.array(
                        penalty_function_ref_value).reshape((1, -1)).repeat(
                        repeats=bs, axis=0)
                    if eval_noise_type == "const":
                        # first add noise, then repeat for each timestep
                        rand_sig = rand_sig0 + eval_noise_std*np.random.normal(
                            size=rand_sig0.shape)
                        rand_sig = rand_sig.reshape((1, bs, -1)).repeat(
                            repeats=nb_steps, axis=0)
                    elif eval_noise_type == "nonconst":
                        # first repeat for each timestep, then add noise
                        rand_sig0 = rand_sig0.reshape((1, bs, -1)).repeat(
                            repeats=nb_steps, axis=0)
                        rand_sig = rand_sig0 + eval_noise_std*np.random.normal(
                            size=rand_sig0.shape)
                    elif eval_noise_type == "cumulative":
                        # first repeat for each timestep, then add cum noise
                        rand_sig0 = rand_sig0.reshape((1, bs, -1)).repeat(
                            repeats=nb_steps, axis=0)
                        rand_sig = rand_sig0 + np.cumsum(
                            eval_noise_std/np.sqrt(nb_steps) * np.random.normal(
                                size=rand_sig0.shape), axis=0)
                    noisy_eval = True
                if eval_noise_std_drift is not None:
                    rand_mu0 = np.array(
                        penalty_function_ref_value_drift).reshape(1, -1).repeat(
                        repeats=bs, axis=0)
                    if eval_noise_type == "const":
                        # first add noise, then repeat for each timestep
                        rand_mu = rand_mu0 + eval_noise_std_drift * \
                                  np.random.normal(size=rand_mu0.shape)
                        rand_mu = rand_mu.reshape((1, bs, -1)).repeat(
                            repeats=nb_steps, axis=0)
                    elif eval_noise_type == "nonconst":
                        # first repeat for each timestep, then add noise
                        rand_mu0 = rand_mu0.reshape((1, bs, -1)).repeat(
                            repeats=nb_steps, axis=0)
                        rand_mu = rand_mu0 + eval_noise_std_drift * \
                                  np.random.normal(size=rand_mu0.shape)
                    elif eval_noise_type == "cumulative":
                        # first repeat for each timestep, then add cum noise
                        rand_mu0 = rand_mu0.reshape((1, bs, -1)).repeat(
                            repeats=nb_steps, axis=0)
                        rand_mu = rand_mu0 + np.cumsum(
                            eval_noise_std_drift/np.sqrt(nb_steps) *
                            np.random.normal(size=rand_mu0.shape), axis=0)
                    noisy_eval = True
                if noisy_eval:
                    exp_util_noisy, _, _, _, _, _ = model.evaluate(
                        dWs=dWs, init_vals=init_vals,
                        ref_params=None, ref_params_drift=None,
                        random_sigmas=rand_sig,
                        random_mus=rand_mu)
                    expected_util_with_noisy_sig += exp_util_noisy.detach().numpy()
                if eval_model is not None:
                    # print("eval vs GARCH ...")
                    exp_util_GARCH = model.evaluate_vs_garch(
                        eval_model=eval_model, eval_model_dict=eval_model_dict,
                        nb_rand_params=eval_model_dict["nb_samples"],
                        nb_samples_per_param=1,
                        seed=eval_noise_seed)
                    expected_util_with_GARCH += exp_util_GARCH
                if ref_strategy is not None:
                    exp_util_ref_strategy, _, _, _, _, _ = model.evaluate(
                        dWs=dWs, init_vals=init_vals,
                        ref_params=None, ref_params_drift=None,
                        random_sigmas=None,
                        random_mus=None, ref_strategy=ref_strategy)
                    expected_util_with_ref_strategy += \
                        exp_util_ref_strategy.detach().numpy()

                    if noisy_eval:
                        exp_util_noisy_ref_strategy, _, _, _, _, _ = model.evaluate(
                            dWs=dWs, init_vals=init_vals,
                            ref_params=None, ref_params_drift=None,
                            random_sigmas=rand_sig,
                            random_mus=rand_mu,
                            ref_strategy=ref_strategy)
                        expected_util_noisy_ref_strat += \
                            exp_util_noisy_ref_strategy.detach().numpy()

                count += 1
            expected_util /= count
            penalty /= count
            penalty_drift /= count
            pwps /= count
            expected_util_with_ref /= count
            expected_util_with_noisy_sig /= count
            expected_util_with_GARCH /= count
            expected_util_with_ref_strategy /= count
            expected_util_noisy_ref_strat /= count
        pwp_scaled_sum = None
        if path_wise_penalty is not None:
            pwp_scaled_sum = np.sum(pwps / pwp_scalings)
        eval_time = time.time() - t
        print("epoch {}, train-time={:.2f}, train-loss-D={:.5f}, "
              "train-loss-G={:.5f}".format(
                model.epoch, train_time, train_loss_D, train_loss_G))
        print("epoch {}, eval-time={:.2f}, eval-expected_utility={:.5f}, "
              "eval-penalty={:.5f}, eval-penalty-drift={}\n"
              "path-wise-eval-penalties: {}\n"
              "analytic-sol-expected_utility={}, "
              "analytic-sol-penalty={}, "
              "analytic-sol-penalty-drift={}".format(
            model.epoch, eval_time, expected_util, penalty, penalty_drift, pwps,
            analytic_exp_util, analytic_penalty, analytic_penalty_drift))
        print("eval-expected_util_with_analytic_par={}, "
              "eval-penalty_vs_analytic_sig={}, "
              "eval-penalty-drift_vs_analytic_mu={},".format(
            expected_util_with_ref, penalty_vs_ref, penalty_drift_vs_ref))
        if path_wise_penalty is not None:
            print("path-wise-penalty-scaled-sum: {:.5f}".format(pwp_scaled_sum))
        if eval_noise_std is not None:
            print("eval-expected_util_with_noisy_par={:.5f}".format(
                expected_util_with_noisy_sig))
        if eval_model is not None:
            print("eval-expected_util_with_GARCH={:.5f}".format(
                expected_util_with_GARCH))
        if ref_strategy is not None:
            print("eval-expected_util_with_ref_strategy={:.5f}".format(
                expected_util_with_ref_strategy))
            print("eval-expected_util_noisy_ref_strategy={:.5f}".format(
                expected_util_noisy_ref_strat))
        if analytic_exp_util is not None:
            eval_dist = analytic_exp_util - expected_util_with_ref
        else:
            eval_dist = None
        metric_app.append(
            [model.epoch, train_time, eval_time, train_loss_D, train_loss_G,
             expected_util, penalty, penalty_drift, pwps,
             analytic_exp_util, analytic_penalty, analytic_penalty_drift,
             eval_dist,
             expected_util_with_ref, penalty_vs_ref, penalty_drift_vs_ref,
             expected_util_with_noisy_sig, expected_util_with_GARCH,
             pwp_scaled_sum, expected_util_with_ref_strategy,
             expected_util_noisy_ref_strat])
        df_m_app = pd.DataFrame(data=metric_app, columns=metr_columns)

        # save model
        if eval_only or model.epoch % save_every == 0:
            print('save model ...')
            df_metric = pd.concat([df_metric, df_m_app], ignore_index=True)
            models.save_checkpoint(
                model, [optimizer_G, optimizer_D],
                [scheduler_G, scheduler_D], model_path_save_last,
                model.epoch)
            df_metric.to_csv(model_metric_file)
            metric_app = []
            print('saved Model!')
        tocompare = df_m_app[which_best].values[-1]
        if (best_is_small and (tocompare < best_eval_loss)) or \
                ((not best_is_small) and (tocompare > best_eval_loss)):
            print('save new best model: last-best-value: {:.5f}, '
                  'new-best-value: {:.5f}, epoch: {}'.format(
                    best_eval_loss, tocompare, model.epoch))
            df_m_app = pd.DataFrame(data=metric_app, columns=metr_columns)
            df_metric = pd.concat([df_metric, df_m_app], ignore_index=True)
            models.save_checkpoint(
                model, [optimizer_G, optimizer_D],
                [scheduler_G, scheduler_D], model_path_save_last,
                model.epoch)
            models.save_checkpoint(
                model, [optimizer_G, optimizer_D],
                [scheduler_G, scheduler_D], model_path_save_best,
                model.epoch)
            df_metric.to_csv(model_metric_file)
            metric_app = []
            best_eval_loss = tocompare
            print('saved Model!')
        if not eval_only:
            model.epoch += 1

    # ---------------- TRAINING ----------------
    skip_training = True
    eval_only = False
    if 'eval_only' in options:
        eval_only = options['eval_only']
    if model.epoch <= epochs or eval_only:
        skip_training = False

        # send notification
        if SEND and not eval_only:
            SBM.send_notification(
                text='start training - model_id={}'.format(model_id),
                chat_id=CHAT_ID
            )
        initial_print += '\n\nmodel overview:'
        print(initial_print)
        print(model, '\n')

        # compute number of parameters P
        nr_params = 0
        for name, param in model.named_parameters():
            skip = False
            if ANOMALY_DETECTION:
                print(name, param)
            for p_name in []:
                if p_name in name:
                    skip = True
            if not skip:
                nr_params += param.nelement()
        print('#parameters = {}'.format(nr_params))

        # compute number of trainable params
        nr_trainable_params = 0
        if optimizer_G is not None:
            for pg in optimizer_G.param_groups:
                for p in pg['params']:
                    nr_trainable_params += p.nelement()
        print('# trainable parameters generator={}'.format(
            nr_trainable_params))
        nr_trainable_params = 0
        if optimizer_D is not None:
            for pg in optimizer_D.param_groups:
                for p in pg['params']:
                    nr_trainable_params += p.nelement()
        print('# trainable parameters discriminator={}\n'.format(
            nr_trainable_params))
        print('start training ...')

    if eval_only:
        one_epoch(eval_only=eval_only)
        return 0

    # -------------- TRAINING LOOP -------------
    while model.epoch <= epochs:
        train_gen_or_disc = None
        if epochs_D_G is not None:
            if (model.epoch-1) % sum(epochs_D_G) < epochs_D_G[0]:
                train_gen_or_disc = 0
            else:
                train_gen_or_disc = 1
        one_epoch(train_gen_or_disc=train_gen_or_disc)

    # ------------ END OF TRAINING --------------
    # send notification
    if SEND and not skip_training:
        files_to_send = [model_metric_file]
        caption = "id={}".format(model_id)
        SBM.send_notification(
            text='finished training: id={}\n\n{}'.format(model_id, desc),
            files=files_to_send,
            text_for_files=caption,
            chat_id=CHAT_ID)

    # delete model & free memory
    del model, dl_train, dl_val, data_train, data_val
    gc.collect()

    return 0



if __name__ == '__main__':
    pass


